{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Q1. What is Bayes' theorem?\n",
        "\n",
        "##Ans:--\n",
        "\n",
        "\n",
        "###Bayes' theorem is a mathematical formula that describes the probability of an event occurring based on prior knowledge of related events. It is named after the 18th-century statistician and theologian Thomas Bayes.\n",
        "\n",
        "###The theorem states that the probability of an event A occurring, given that event B has occurred, can be calculated using the following formula:\n",
        "\n",
        "```\n",
        "P(A|B) = (P(B|A) * P(A)) / P(B)\n",
        "\n",
        "where:\n",
        "P(A|B) is the probability of event A occurring given that event B has occurred,\n",
        "P(B|A) is the probability of event B occurring given that event A has occurred,\n",
        "P(A) is the prior probability of event A occurring,\n",
        "P(B) is the prior probability of event B occurring.\n",
        "```\n",
        "###In other words, Bayes' theorem helps us update our belief in the likelihood of an event occurring based on new evidence or information."
      ],
      "metadata": {
        "id": "uHid2eu7cy_K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q2. What is the formula for Bayes' theorem?\n",
        "\n",
        "##Ans:---\n",
        "\n",
        "\n",
        "```\n",
        "P(A|B) = (P(B|A) * P(A)) / P(B)\n",
        "\n",
        "where:\n",
        "P(A|B) is the probability of event A occurring given that event B has occurred,\n",
        "P(B|A) is the probability of event B occurring given that event A has occurred,\n",
        "P(A) is the prior probability of event A occurring,\n",
        "P(B) is the prior probability of event B occurring.\n",
        "```"
      ],
      "metadata": {
        "id": "CKbqU_h-c9GK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q3. How is Bayes' theorem used in practice?\n",
        "\n",
        "##Ans:--\n",
        "\n",
        "###Bayes' theorem is used in many fields, including statistics, machine learning, artificial intelligence, and decision-making. Some examples of how it is used in practice include:\n",
        "\n",
        "* Medical diagnosis: Bayes' theorem can be used to calculate the probability of a patient having a certain disease based on symptoms, test results, and other factors.\n",
        "\n",
        "* Spam filtering: Email providers often use Bayes' theorem to filter out spam emails by calculating the probability that a message is spam based on its content and other factors.\n",
        "\n",
        "* Predictive modeling: In machine learning, Bayes' theorem is used to estimate the probability of an outcome based on training data and prior knowledge.\n",
        "\n",
        "* Risk analysis: Bayes' theorem can be used to assess the probability of certain events, such as accidents, natural disasters, or financial losses, based on historical data and other relevant factors.\n",
        "\n",
        "* Decision-making: Bayes' theorem can help individuals and organizations make better decisions by weighing the probability of different outcomes based on available information and prior experience.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WysA0ZL_dLqH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q4. What is the relationship between Bayes' theorem and conditional probability?\n",
        "\n",
        "##Ans:--\n",
        "\n",
        "###Bayes' theorem is related to conditional probability because it uses conditional probabilities to calculate the probability of an event occurring. Specifically, Bayes' theorem allows us to calculate the conditional probability of an event A given that event B has occurred (i.e., P(A|B)) in terms of the conditional probability of event B given that event A has occurred (i.e., P(B|A)) and the prior probability of event A (i.e., P(A)) and the prior probability of event B (i.e., P(B)).\n",
        "\n",
        "###In other words, Bayes' theorem is a way of updating our prior beliefs about the probability of an event occurring based on new information or evidence (i.e., the conditional probability of event B given event A). This is similar to how conditional probability is used to calculate the probability of an event occurring given some other related event.\n",
        "\n",
        "###Overall, Bayes' theorem provides a framework for understanding how conditional probabilities can be used to update our beliefs about the likelihood of events occurring."
      ],
      "metadata": {
        "id": "U66GOKIidgOV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?\n",
        "\n",
        "##Ans:---\n",
        "\n",
        "###There are three main types of Naive Bayes classifiers: Gaussian, Multinomial, and Bernoulli. The choice of which type to use depends on the nature of the problem and the type of data that is being analyzed.\n",
        "\n",
        "###Here are some guidelines for selecting the appropriate type of Naive Bayes classifier:\n",
        "\n",
        "* Gaussian Naive Bayes: This classifier is appropriate for continuous data that follows a normal distribution, such as height or weight. It assumes that the features are normally distributed and uses the mean and variance of each feature to calculate the conditional probability.\n",
        "\n",
        "* Multinomial Naive Bayes: This classifier is used for discrete data such as text data, where the features represent the frequency of occurrence of certain words. It assumes that the features are generated from a multinomial distribution and uses the count of each feature to calculate the conditional probability.\n",
        "\n",
        "* Bernoulli Naive Bayes: This classifier is similar to the Multinomial Naive Bayes but is used for binary data, where each feature can take on only two values (e.g., 0 or 1). It assumes that the features are generated from a Bernoulli distribution and uses the presence or absence of each feature to calculate the conditional probability.\n",
        "\n",
        "####In general, the choice of Naive Bayes classifier depends on the type of data and the assumptions that are appropriate for the problem. It is often a good idea to try out different classifiers and compare their performance using metrics such as accuracy, precision, recall, or F1 score to determine which one works best for the given problem."
      ],
      "metadata": {
        "id": "KtWVsoNjd4N-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q6. Assignment:\n",
        "\n",
        "###You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of each feature value for each class:\n",
        "```\n",
        "Class X1=1 X1=2 X1=3 X2=1 X2=2 X2=3 X2=4\n",
        "A 3 3 4 4 3 3 3\n",
        "B 2 2 1 2 2 2 3\n",
        "```\n",
        "###Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance to belong to?\n"
      ],
      "metadata": {
        "id": "vjkAB2bpoF30"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###To predict the class of the new instance with features X1=3 and X2=4 using Naive Bayes, we need to calculate the conditional probabilities of each class given these feature values and then choose the class with the highest probability.\n",
        "\n",
        "###First, we can calculate the prior probability of each class, which is assumed to be equal:\n",
        "\n",
        "    P(A) = P(B) = 0.5\n",
        "\n",
        "###Next, we can calculate the conditional probabilities of each class given the feature values:\n",
        "\n",
        "```\n",
        "P(X1=3 | A) = 4/10 = 0.4\n",
        "P(X2=4 | A) = 3/10 = 0.3\n",
        "P(A | X1=3, X2=4) = P(X1=3 | A) * P(X2=4 | A) * P(A) = 0.4 * 0.3 * 0.5 = 0.06\n",
        "\n",
        "P(X1=3 | B) = 1/7 ≈ 0.143\n",
        "P(X2=4 | B) = 1/7 ≈ 0.143\n",
        "P(B | X1=3, X2=4) = P(X1=3 | B) * P(X2=4 | B) * P(B) ≈ 0.143 * 0.143 * 0.5 ≈ 0.01\n",
        "```\n",
        "###Therefore, according to Naive Bayes, the new instance with features X1=3 and X2=4 is predicted to belong to class A, as it has a higher conditional probability of 0.06 compared to 0.01 for class B."
      ],
      "metadata": {
        "id": "KTVdHOF_o907"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BwA-h-QubzHw"
      },
      "outputs": [],
      "source": []
    }
  ]
}